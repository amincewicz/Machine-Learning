{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the two files we were provided with into pandas dataframses\n",
    "data_test = pd.read_csv('fashion-mnist_test.csv')\n",
    "data_train = pd.read_csv('fashion-mnist_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The data that we have still needs to be split into training and test, Y and X \n",
    "test_X=data_test.drop([\"label\"], axis=1)\n",
    "test_Y=data_test[\"label\"]\n",
    "train_X=data_train.drop([\"label\"], axis=1)\n",
    "train_Y=data_train[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here the data is converted into numpy arrays so it can later be fit into the chosen model\n",
    "X_train = np.asarray(train_X)\n",
    "Y_train = np.asarray(train_Y)\n",
    "X_test = np.asarray(test_X)\n",
    "Y_test = np.asarray(test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use a funtion to create a model and pass number of layers and neurons. We also have to set initial weights \n",
    "def create_model(num_layer, num_neuron):\n",
    "    model = tf.keras.Sequential()\n",
    "    kernel_initializer = tf.keras.initializers.RandomNormal(mean=0.0, stddev=2 / np.sqrt(len(X_train) + num_neuron))\n",
    "    model.add(tf.keras.layers.Dense(num_neuron, input_shape=(28 * 28,), activation=\"relu\", kernel_initializer=kernel_initializer))\n",
    "    for i in range(num_layer):\n",
    "        model.add(tf.keras.layers.Dense(num_neuron, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we have to find he hyperparameters that have the highest accuracy. Random Search is used for that. \n",
    "#We are also choosing the layers: 1, 2, 3, 4. And also chhosing neurons: 96, 112, 128, 144\n",
    "num_layer = [1, 2, 3, 4]\n",
    "num_neuron = [96, 112, 128, 144]\n",
    "param_dist = dict(num_layer=num_layer, num_neuron=num_neuron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "                   estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x00000164E3F57D08>,\n",
       "                   iid='warn', n_iter=10, n_jobs=None,\n",
       "                   param_distributions={'num_layer': [1, 2, 3, 4],\n",
       "                                        'num_neuron': [96, 112, 128, 144]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we have to create an esimator to pass into the random search function. Number of epochs 40 and batch size 500\n",
    "model = tf.keras.wrappers.scikit_learn.KerasClassifier(build_fn=create_model, epochs=40, batch_size=500, verbose=0)\n",
    "random_search = RandomizedSearchCV(estimator=model,param_distributions=param_dist, n_iter=10, cv=3)\n",
    "random_search.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest accuracy is:  0.8789666692415873  with the use of  {'num_neuron': 144, 'num_layer': 3}\n",
      "The accuracy of  0.8789666692415873  with the use of  [0.87395    0.87578332 0.85946667 0.86443333 0.86860001 0.87644998\n",
      " 0.86216666 0.86528331 0.87896667 0.86113334] [0.00063378 0.00198591 0.00251142 0.00252332 0.00648113 0.00271755\n",
      " 0.00198089 0.00690656 0.00409966 0.0073467 ] {'num_neuron': 128, 'num_layer': 3}\n",
      "The accuracy of  0.8789666692415873  with the use of  [0.87395    0.87578332 0.85946667 0.86443333 0.86860001 0.87644998\n",
      " 0.86216666 0.86528331 0.87896667 0.86113334] [0.00063378 0.00198591 0.00251142 0.00252332 0.00648113 0.00271755\n",
      " 0.00198089 0.00690656 0.00409966 0.0073467 ] {'num_neuron': 112, 'num_layer': 3}\n",
      "The accuracy of  0.8789666692415873  with the use of  [0.87395    0.87578332 0.85946667 0.86443333 0.86860001 0.87644998\n",
      " 0.86216666 0.86528331 0.87896667 0.86113334] [0.00063378 0.00198591 0.00251142 0.00252332 0.00648113 0.00271755\n",
      " 0.00198089 0.00690656 0.00409966 0.0073467 ] {'num_neuron': 96, 'num_layer': 1}\n",
      "The accuracy of  0.8789666692415873  with the use of  [0.87395    0.87578332 0.85946667 0.86443333 0.86860001 0.87644998\n",
      " 0.86216666 0.86528331 0.87896667 0.86113334] [0.00063378 0.00198591 0.00251142 0.00252332 0.00648113 0.00271755\n",
      " 0.00198089 0.00690656 0.00409966 0.0073467 ] {'num_neuron': 96, 'num_layer': 4}\n",
      "The accuracy of  0.8789666692415873  with the use of  [0.87395    0.87578332 0.85946667 0.86443333 0.86860001 0.87644998\n",
      " 0.86216666 0.86528331 0.87896667 0.86113334] [0.00063378 0.00198591 0.00251142 0.00252332 0.00648113 0.00271755\n",
      " 0.00198089 0.00690656 0.00409966 0.0073467 ] {'num_neuron': 96, 'num_layer': 3}\n",
      "The accuracy of  0.8789666692415873  with the use of  [0.87395    0.87578332 0.85946667 0.86443333 0.86860001 0.87644998\n",
      " 0.86216666 0.86528331 0.87896667 0.86113334] [0.00063378 0.00198591 0.00251142 0.00252332 0.00648113 0.00271755\n",
      " 0.00198089 0.00690656 0.00409966 0.0073467 ] {'num_neuron': 144, 'num_layer': 4}\n",
      "The accuracy of  0.8789666692415873  with the use of  [0.87395    0.87578332 0.85946667 0.86443333 0.86860001 0.87644998\n",
      " 0.86216666 0.86528331 0.87896667 0.86113334] [0.00063378 0.00198591 0.00251142 0.00252332 0.00648113 0.00271755\n",
      " 0.00198089 0.00690656 0.00409966 0.0073467 ] {'num_neuron': 128, 'num_layer': 1}\n",
      "The accuracy of  0.8789666692415873  with the use of  [0.87395    0.87578332 0.85946667 0.86443333 0.86860001 0.87644998\n",
      " 0.86216666 0.86528331 0.87896667 0.86113334] [0.00063378 0.00198591 0.00251142 0.00252332 0.00648113 0.00271755\n",
      " 0.00198089 0.00690656 0.00409966 0.0073467 ] {'num_neuron': 96, 'num_layer': 2}\n",
      "The accuracy of  0.8789666692415873  with the use of  [0.87395    0.87578332 0.85946667 0.86443333 0.86860001 0.87644998\n",
      " 0.86216666 0.86528331 0.87896667 0.86113334] [0.00063378 0.00198591 0.00251142 0.00252332 0.00648113 0.00271755\n",
      " 0.00198089 0.00690656 0.00409966 0.0073467 ] {'num_neuron': 144, 'num_layer': 3}\n",
      "The accuracy of  0.8789666692415873  with the use of  [0.87395    0.87578332 0.85946667 0.86443333 0.86860001 0.87644998\n",
      " 0.86216666 0.86528331 0.87896667 0.86113334] [0.00063378 0.00198591 0.00251142 0.00252332 0.00648113 0.00271755\n",
      " 0.00198089 0.00690656 0.00409966 0.0073467 ] {'num_neuron': 144, 'num_layer': 1}\n"
     ]
    }
   ],
   "source": [
    "print(\"Highest accuracy is: \",random_search.best_score_,\" with the use of \", random_search.best_params_)\n",
    "mean_score = random_search.cv_results_[\"mean_test_score\"]\n",
    "std_score = random_search.cv_results_[\"std_test_score\"]\n",
    "params = random_search.cv_results_[\"params\"]\n",
    "for mean, stdev, param in zip(mean_score, std_score, params):\n",
    "    print(\"The accuracy of \",random_search.best_score_,\" with the use of \",mean_score, std_score, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "60000/60000 [==============================] - 8s 133us/sample - loss: 0.7992 - accuracy: 0.7766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16508108f88>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We have to now fit the final model with the best hyperparameters\n",
    "final_model_hyperpar=create_model(random_search.best_params_[\"num_layer\"], random_search.best_params_[\"num_neuron\"])\n",
    "final_model_hyperpar.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy is  0.832\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the final model and its final accuracy\n",
    "final_result = final_model_hyperpar.evaluate(X_test,Y_test, verbose=0)\n",
    "print(\"Final accuracy is \", final_result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
